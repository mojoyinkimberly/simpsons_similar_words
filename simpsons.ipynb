{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from gensim.models.phrases import  Phrases, Phraser\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "        raw_character_text                                       spoken_words\n0              Miss Hoover  No, actually, it was a little of both. Sometim...\n1             Lisa Simpson                             Where's Mr. Bergstrom?\n2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n3             Lisa Simpson                         That life is worth living.\n4  Edna Krabappel-Flanders  The polls will be open from now until the end ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_character_text</th>\n      <th>spoken_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Miss Hoover</td>\n      <td>No, actually, it was a little of both. Sometim...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lisa Simpson</td>\n      <td>Where's Mr. Bergstrom?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Miss Hoover</td>\n      <td>I don't know. Although I'd sure like to talk t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lisa Simpson</td>\n      <td>That life is worth living.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Edna Krabappel-Flanders</td>\n      <td>The polls will be open from now until the end ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpsons_data = pd.read_csv(\"~/Downloads/simpsons_dataset.csv\", sep = \",\")\n",
    "simpsons_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "raw_character_text    17814\nspoken_words          26459\ndtype: int64"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpsons_data.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "new_simpsons =simpsons_data.dropna().reset_index(drop = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "clean_data = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in new_simpsons['spoken_words'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "(119516, 1)"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_simp = pd.DataFrame({'clean': clean_data})\n",
    "clean_simp = clean_simp.dropna().drop_duplicates()\n",
    "clean_simp.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bigram we are using gensim phrases package to automatically detect common phrases(bigrams) from a list of sentences. Using the bigram model to catch or capture words like \"mr_burns\" or \"bart_simpson\"!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "sentence = [row.split() for row in clean_simp['clean']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creates the relevant phrases from the list of sentences:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "phrases = Phrases(sentence, min_count=30, progress_per=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenizing sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "sentences_ = bigram[sentence]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "40991"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency = defaultdict(int)\n",
    "for sentence in sentences_:\n",
    "    for i in sentence:\n",
    "        word_frequency[i] += 1\n",
    "len(word_frequency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "getting frequent words from the documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "['the', 'you', 'i', 'a', 'to', 'and', 'of', 'it', 'my', 'that']"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_frequency, key=word_frequency.get, reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "training the model using the gensim word2vec model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count() #count the number of cores in a computer\n",
    "cores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20, #ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "                     window=6,\n",
    "                     size=300, #dimensionality of the feature vectors. - (50, 300)\n",
    "                     sample=6e-5, #The threshold for configuring which higher -frequency words are randomly downsampled. Highly influencial. -(0, 1e-5)\n",
    "                     alpha=0.03, #The initial learning rate -(0.01, 0.05)\n",
    "                     min_alpha=0.0007, #learning rate will linearly drop to min_alpha as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00\n",
    "                     negative=20, #if > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown. If set to 0,negative sampling is used. - (5, 20)\n",
    "                     workers=cores-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentences_, progress_per=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "(12599243, 37627050)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "(12599243, 37627050)"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences_, total_examples = w2v_model.corpus_count, epochs=30, report_delay=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "[('marge', 0.5678250193595886),\n ('dad', 0.4641968011856079),\n ('homie', 0.4537961483001709),\n ('becky', 0.40316736698150635),\n ('bart', 0.39305901527404785),\n ('gee', 0.39249613881111145),\n ('abe', 0.38196370005607605),\n ('mom', 0.378150999546051),\n ('son', 0.3679531216621399),\n ('honey', 0.36209654808044434)]"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "[('marge', 0.567729115486145),\n ('dad', 0.4640953242778778),\n ('homie', 0.45330923795700073),\n ('becky', 0.4027969241142273),\n ('bart', 0.3929387331008911),\n ('gee', 0.392608106136322),\n ('abe', 0.38157254457473755),\n ('mom', 0.37801483273506165),\n ('son', 0.36788779497146606),\n ('honey', 0.3620525002479553)]"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['homer'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "checking for similarities between words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4034/388778661.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  w2v_model.similarity(\"mom\", \"dad\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7336106524568102"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4034/388778661.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  w2v_model.similarity(\"mom\", \"dad\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7337602817219319"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.similarity(\"mom\", \"dad\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "checking for words that did not match from an array of words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4034/163752122.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  w2v_model.doesnt_match(['good','smooth','cute'])\n",
      "/home/kimberly/PycharmProjects/pythonProject4/venv/lib/python3.8/site-packages/gensim/models/keyedvectors.py:730: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'smooth'"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4034/163752122.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  w2v_model.doesnt_match(['good','smooth','cute'])\n",
      "/home/kimberly/PycharmProjects/pythonProject4/venv/lib/python3.8/site-packages/gensim/models/keyedvectors.py:730: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'smooth'"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.doesnt_match(['good','smooth','cute'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}